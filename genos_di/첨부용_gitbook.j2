# ì§€ëŠ¥í˜• ë¬¸ì„œ ì „ì²˜ë¦¬ê¸° - ì²¨ë¶€ìš©

ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì˜ ì²¨ë¶€ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ëŠ” ë²”ìš© ì „ì²˜ë¦¬ê¸°ì…ë‹ˆë‹¤. PDF, ì˜¤í”¼ìŠ¤ ë¬¸ì„œ, ì´ë¯¸ì§€, í‘œ ë°ì´í„° ë“± ê´‘ë²”ìœ„í•œ íŒŒì¼ í˜•ì‹ì„ ì§€ì›í•©ë‹ˆë‹¤.

## ğŸ”§ ê³µí†µ ì»´í¬ë„ŒíŠ¸

### GenOSVectorMeta (ì²¨ë¶€ìš© ë²„ì „)
ì²¨ë¶€ ë¬¸ì„œìš© ë©”íƒ€ë°ì´í„° ëª¨ë¸ì…ë‹ˆë‹¤.

```python
class GenOSVectorMeta(BaseModel):
    class Config:
        extra = 'allow'
    
    text: str | None = None
    n_char: int | None = None       # ë¬¸ì ìˆ˜
    n_word: int | None = None       # ë‹¨ì–´ ìˆ˜
    n_line: int | None = None       # ì¤„ ìˆ˜
    i_page: int | None = None       # ì‹œì‘ í˜ì´ì§€
    e_page: int | None = None       # ì¢…ë£Œ í˜ì´ì§€ â˜…ì²¨ë¶€ìš© ì „ìš©
    i_chunk_on_page: int | None = None
    n_chunk_of_page: int | None = None    # í˜ì´ì§€ ë‚´ ì´ ì²­í¬ ìˆ˜
    i_chunk_on_doc: int | None = None
    n_chunk_of_doc: int | None = None
    n_page: int | None = None       # ì´ í˜ì´ì§€ ìˆ˜
    reg_date: str | None = None
    chunk_bboxes: str | None = None
    media_files: str | None = None
```

### GenOSVectorMetaBuilder (ì²¨ë¶€ìš© ë²„ì „)
```python
class GenOSVectorMetaBuilder:
    def set_text(self, text: str) -> "GenOSVectorMetaBuilder":
        """í…ìŠ¤íŠ¸ì™€ ê´€ë ¨ í†µê³„ ì„¤ì •"""
        self.text = text
        self.n_char = len(text)
        self.n_word = len(text.split())
        self.n_line = len(text.splitlines())
        return self
    
    def set_chunk_bboxes(self, doc_items: list, document: DoclingDocument):
        """e_page í•„ë“œ ìë™ ê³„ì‚°"""
        chunk_bboxes = []
        for item in doc_items:
            for prov in item.prov:
                # ... ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚° ...
                chunk_bboxes.append({
                    'page': page_no,
                    'bbox': bbox_data,
                    'type': type_,
                    'ref': label
                })
        
        # ì¢…ë£Œ í˜ì´ì§€ ìë™ ì„¤ì •
        self.e_page = max([bbox['page'] for bbox in chunk_bboxes]) if chunk_bboxes else None
        self.chunk_bboxes = json.dumps(chunk_bboxes)
        return self
```

### DocumentProcessor
ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ì„ ì²˜ë¦¬í•˜ëŠ” ë©”ì¸ í”„ë¡œì„¸ì„œì…ë‹ˆë‹¤.

```python
class DocumentProcessor:
    def __init__(self):
        self.page_chunk_counts = defaultdict(int)
        self.hwpx_processor = HwpxProcessor()  # HWPX ì „ìš© í”„ë¡œì„¸ì„œ
    
    def get_loader(self, file_path: str):
        """íŒŒì¼ í™•ì¥ìë³„ ì ì ˆí•œ ë¡œë” ì„ íƒ"""
        ext = os.path.splitext(file_path)[-1].lower()
        
        if ext == '.pdf':
            return PyMuPDFLoader(file_path)
        elif ext in ['.doc', '.docx']:
            return UnstructuredWordDocumentLoader(file_path)
        elif ext in ['.ppt', '.pptx']:
            return UnstructuredPowerPointLoader(file_path)
        elif ext in ['.jpg', '.jpeg', '.png']:
            return UnstructuredImageLoader(file_path)
        elif ext in ['.txt', '.json']:
            return TextLoader(file_path)  # ì»¤ìŠ¤í…€ ë¡œë”
        elif ext == '.hwp':
            return HwpLoader(file_path)  # ì»¤ìŠ¤í…€ ë¡œë”
        elif ext == '.md':
            return UnstructuredMarkdownLoader(file_path)
        else:
            return UnstructuredFileLoader(file_path)  # ë²”ìš© í´ë°±
```

### íŠ¹ìˆ˜ íŒŒì¼ ë¡œë”

#### HwpLoader (HWP â†’ PDF ë³€í™˜)
```python
class HwpLoader:
    def __init__(self, file_path: str):
        self.file_path = file_path
        self.output_dir = os.path.join('/tmp', str(uuid.uuid4()))
        os.makedirs(self.output_dir, exist_ok=True)
    
    def load(self):
        # HWP â†’ XHTML ë³€í™˜
        subprocess.run(['hwp5html', self.file_path, '--output', self.output_dir], 
                      check=True, timeout=600)
        
        # XHTML â†’ PDF ë³€í™˜
        converted_file_path = os.path.join(self.output_dir, 'index.xhtml')
        pdf_save_path = self.file_path.replace('.hwp', '.pdf')
        HTML(converted_file_path).write_pdf(pdf_save_path)
        
        # PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        loader = PyMuPDFLoader(pdf_save_path)
        return loader.load()
```

#### TextLoader (í…ìŠ¤íŠ¸ â†’ PDF ë³€í™˜)
```python
class TextLoader:
    def load(self):
        # ì¸ì½”ë”© ìë™ ê°ì§€
        with open(self.file_path, 'rb') as f:
            raw_file = f.read(100)
        enc_type = chardet.detect(raw_file)['encoding']
        
        # HTMLë¡œ ë˜í•‘ (í¬ë§· ë³´ì¡´)
        with open(self.file_path, 'r', encoding=enc_type) as f:
            content = f.read()
        html_content = f"<html><body><pre>{content}</pre></body></html>"
        
        # PDF ë³€í™˜
        HTML(html_file_path).write_pdf(pdf_save_path)
        loader = PyMuPDFLoader(pdf_save_path)
        return loader.load()
```

#### TabularLoader (CSV/XLSX â†’ JSON)
```python
class TabularLoader:
    def check_sql_dtypes(self, df):
        """SQL ë°ì´í„° íƒ€ì… ìë™ ì¶”ë¡ """
        for col in df.columns:
            dtype = str(df.dtypes[col]).lower()
            
            if 'int' in dtype:
                sql_dtype = 'BIGINT' if '64' in dtype else 'INT'
            elif 'float' in dtype:
                sql_dtype = 'FLOAT'
            elif 'bool' in dtype:
                sql_dtype = 'BOOLEAN'
            elif 'date' in dtype:
                sql_dtype = 'DATE'
            elif 'datetime' in dtype:
                sql_dtype = 'DATETIME'
            else:
                max_len = df[col].str.len().max() + 10
                sql_dtype = f'VARCHAR({max_len})'
    
    def load_xlsx_documents(self, file_path: str):
        """ë‹¤ì¤‘ ì‹œíŠ¸ ì²˜ë¦¬"""
        dfs = pd.read_excel(file_path, sheet_name=None)
        for sheet_name, df in dfs.items():
            df = df.fillna('null')
            # ê° ì‹œíŠ¸ë³„ ì²˜ë¦¬
    
    def return_vectormeta_format(self):
        """[DA] ì ‘ë‘ì‚¬ë¡œ ë°ì´í„° ë¶„ì„ìš© í‘œì‹œ"""
        text = "[DA] " + str(self.data_dict)
        return [GenOSVectorMeta.model_validate({
            'text': text,
            # ... ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ...
        })]
```

## ğŸ“‚ ì „ì²˜ë¦¬ íë¦„

### 1. íŒŒì¼ í˜•ì‹ë³„ ë¶„ê¸° ì²˜ë¦¬
```python
async def __call__(self, request: Request, file_path: str, **kwargs: dict):
    ext = os.path.splitext(file_path)[-1].lower()
    
    # í‘œ ë°ì´í„°
    if ext in ('.csv', '.xlsx'):
        loader = TabularLoader(file_path, ext)
        vectors = loader.return_vectormeta_format()
        return vectors
    
    # HWPX
    elif ext in ('.hwpx'):
        return await self.hwpx_processor(request, file_path, **kwargs)
    
    # ì¼ë°˜ ë¬¸ì„œ
    else:
        documents = self.load_documents(file_path, **kwargs)
        chunks = self.split_documents(documents, **kwargs)
        vectors = await self.compose_vectors(chunks, file_path, request, **kwargs)
        return vectors
```

### 2. ì¼ë°˜ ë¬¸ì„œ ë¡œë“œ
```python
def load_documents(self, file_path: str, **kwargs: dict) -> list[Document]:
    loader = self.get_loader(file_path)
    documents = loader.load()
    return documents
```

### 3. ë¬¸ì„œ ì²­í‚¹ (LangChain)
```python
def split_documents(self, documents: list[Document], **kwargs: dict) -> list[Document]:
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=2000,       # ì²­í¬ í¬ê¸°
        chunk_overlap=200,     # ì˜¤ë²„ë©
        separators=["\n\n", "\n", " ", ""]
    )
    chunks = text_splitter.split_documents(documents)
    
    # í˜ì´ì§€ë³„ ì²­í¬ ìˆ˜ ê³„ì‚°
    for chunk in chunks:
        page = chunk.metadata.get('page', 0)
        self.page_chunk_counts[page] += 1
    
    return chunks
```

### 4. ë²¡í„° ë©”íƒ€ë°ì´í„° ìƒì„± (ì²¨ë¶€ìš©)
```python
async def compose_vectors(self, chunks: list[Document], file_path: str, 
                          request: Request, **kwargs: dict) -> list[dict]:
    # ê¸€ë¡œë²Œ ë©”íƒ€ë°ì´í„°
    global_metadata = dict(
        n_chunk_of_doc=len(chunks),
        n_page=max([c.metadata.get('page', 0) for c in chunks]) + 1,
        reg_date=datetime.now().isoformat(timespec='seconds') + 'Z'
    )
    
    vectors = []
    for chunk_idx, chunk in enumerate(chunks):
        page = chunk.metadata.get('page', 0)
        
        vector = (GenOSVectorMetaBuilder()
                  .set_text(chunk.page_content)
                  .set_page_info(page, self.page_chunk_counts[page], self.page_chunk_counts[page])
                  .set_chunk_index(chunk_idx)
                  .set_global_metadata(**global_metadata)
                  ).build()
        
        # e_page ì„¤ì • (ì²¨ë¶€ìš© ì „ìš©)
        vector.e_page = page
        vectors.append(vector)
    
    return vectors
```

### 5. HWPX ì²˜ë¦¬ (Docling)
```python
class HwpxProcessor:
    def __init__(self):
        self.converter = DocumentConverter(
            format_options={
                InputFormat.HWPX: HwpxFormatOption(
                    pipeline_options=pipeline_options
                )
            }
        )
    
    async def __call__(self, request: Request, file_path: str, **kwargs):
        document = self.load_documents(file_path)
        
        # HybridChunker ì‚¬ìš© (Docling ë°©ì‹)
        chunker = HybridChunker(max_tokens=2000, merge_peers=True)
        chunks = list(chunker.chunk(dl_doc=document))
        
        vectors = await self.compose_vectors(document, chunks, file_path, request)
        return vectors
```

## âœ… ìœ ì§€ë³´ìˆ˜ íŒ

### ì§€ì› íŒŒì¼ í˜•ì‹ ìš”ì•½
| í˜•ì‹ | ë¡œë” | íŠ¹ì´ì‚¬í•­ |
|------|------|----------|
| PDF | PyMuPDFLoader | ì§ì ‘ ì²˜ë¦¬ |
| DOC/DOCX | UnstructuredWordDocumentLoader | ì§ì ‘ ì²˜ë¦¬ |
| PPT/PPTX | UnstructuredPowerPointLoader | ì§ì ‘ ì²˜ë¦¬ |
| JPG/PNG | UnstructuredImageLoader | ì§ì ‘ ì²˜ë¦¬ |
| TXT/JSON | TextLoader | PDF ë³€í™˜ í›„ ì²˜ë¦¬ |
| HWP | HwpLoader | XHTMLâ†’PDF ë³€í™˜ |
| HWPX | HwpxProcessor | Docling ë„¤ì´í‹°ë¸Œ |
| CSV/XLSX | TabularLoader | [DA] ì ‘ë‘ì‚¬, SQL íƒ€ì… ì¶”ë¡  |
| MD | UnstructuredMarkdownLoader | ì§ì ‘ ì²˜ë¦¬ |

